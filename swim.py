# -*- coding: utf-8 -*-
"""Swim.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hg7vIJODdhLfTSyCCUQfdxfCs9FKmuGX
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from transformers import AutoFeatureExtractor, SwinForImageClassification
from sklearn.metrics import accuracy_score
import numpy as np
from google.colab import drive

drive.mount('/content/drive')

# Define image transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Correct path setup
DATA_DIR = '/content/drive/MyDrive/data'  # Ensure this path matches your Google Drive setup

# Load dataset (use corrected paths)
train_data = datasets.ImageFolder(root=DATA_DIR + '/train', transform=transform)
test_data = datasets.ImageFolder(root=DATA_DIR + '/test', transform=transform)



# Ensure this path matches your Google Drive setup
MODEL_NAME = "microsoft/swin-tiny-patch4-window7-224"

train_loader = DataLoader(train_data, batch_size=16, shuffle=True) # small no of epochs replicate
test_loader = DataLoader(test_data, batch_size=16, shuffle=False)

# Load Swin Transformer model with ignore_mismatched_sizes=True
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SwinForImageClassification.from_pretrained(
    MODEL_NAME,
    num_labels=len(train_data.classes),
    ignore_mismatched_sizes=True
).to(device)

# Update the classifier layer to match the number of classes
model.classifier = nn.Linear(model.classifier.in_features, len(train_data.classes)).to(device)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# Training loop
num_epochs = 50
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images).logits
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}")

# Evaluation
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images).logits
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

accuracy = accuracy_score(all_labels, all_preds)
print(f"Test Accuracy: {accuracy:.4f}")

# Import necessary libraries for metrics
from sklearn.metrics import accuracy_score, f1_score

# Evaluation
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images).logits
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calculate Accuracy and F1 Score
accuracy = accuracy_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds, average='weighted')  # Use 'weighted' for multi-class, 'binary' for binary classification

print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test F1 Score: {f1:.4f}")

# Import necessary libraries for metrics and plotting
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Evaluation
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images).logits
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calculate Accuracy and F1 Score
accuracy = accuracy_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds, average='weighted')  # Use 'weighted' for multi-class

print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test F1 Score: {f1:.4f}")

# Generate Confusion Matrix
conf_matrix = confusion_matrix(all_labels, all_preds)

# Plot the Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=train_data.classes, yticklabels=train_data.classes)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title(f'Confusion Matrix\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}')
plt.show()



# Import necessary libraries
from PIL import Image
import torch
from torchvision import transforms

# Define the transformation for test images (same as training)
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Set model to evaluation mode
model.eval()

# Function to predict class of a single image
def predict_image(image_path, model):
    # Load image
    image = Image.open(image_path).convert('RGB')

    # Apply transformations
    image = test_transform(image)

    # Add batch dimension (1, C, H, W)
    image = image.unsqueeze(0)

    # Move to device
    image = image.to(device)

    # Forward pass through the model
    with torch.no_grad():
        output = model(image).logits
        _, predicted_class = torch.max(output, 1)

    # Convert predicted_class tensor to class name
    class_name = train_data.classes[predicted_class.item()]
    return class_name

# Test the function with an example image
image_path = '/content/drive/MyDrive/data/test/malignant/1141.jpg'  # replace with the path to your image
predicted_class = predict_image(image_path, model)
print(f"The model predicts this image as: {predicted_class}")

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import SwinForImageClassification
from PIL import Image

# Define transformations with data augmentation for training
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Transform for validation/testing
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load datasets
DATA_DIR = '/content/drive/MyDrive/data'
train_data = datasets.ImageFolder(root=DATA_DIR + '/train', transform=train_transform)
test_data = datasets.ImageFolder(root=DATA_DIR + '/test', transform=test_transform)

# Data loaders
train_loader = DataLoader(train_data, batch_size=16, shuffle=True)
test_loader = DataLoader(test_data, batch_size=16, shuffle=False)

# Load Swin Transformer model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
MODEL_NAME = 'microsoft/swin-tiny-patch4-window7-224'
model = SwinForImageClassification.from_pretrained(
    MODEL_NAME,
    num_labels=len(train_data.classes),
    ignore_mismatched_sizes=True
).to(device)

# Update classifier layer to match number of classes
model.classifier = nn.Linear(model.classifier.in_features, len(train_data.classes)).to(device)

# Define loss function and optimizer with lower learning rate
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-5)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # Halve learning rate every 10 epochs

# Training loop with accuracy and early stopping
num_epochs = 50
best_val_accuracy = 0.0
patience = 5  # Early stopping patience
stopping_counter = 0

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct, total = 0, 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images).logits
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_accuracy = 100 * correct / total
    avg_loss = running_loss / len(train_loader)
    scheduler.step()  # Update learning rate

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%")

    # Validation
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images).logits
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate metrics
    val_accuracy = accuracy_score(all_labels, all_preds)
    val_f1 = f1_score(all_labels, all_preds, average='weighted')

    print(f"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}")

    # Early stopping
    if val_accuracy > best_val_accuracy:
        best_val_accuracy = val_accuracy
        stopping_counter = 0  # Reset counter if validation accuracy improves
    else:
        stopping_counter += 1
        if stopping_counter >= patience:
            print("Early stopping triggered.")
            break

# Final evaluation on the test set with confusion matrix
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images).logits
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Final test metrics
test_accuracy = accuracy_score(all_labels, all_preds)
test_f1 = f1_score(all_labels, all_preds, average='weighted')

print(f"Test Accuracy: {test_accuracy:.4f}")
print(f"Test F1 Score: {test_f1:.4f}")

# Confusion Matrix
conf_matrix = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=train_data.classes, yticklabels=train_data.classes)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title(f'Confusion Matrix\nTest Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}')
plt.show()